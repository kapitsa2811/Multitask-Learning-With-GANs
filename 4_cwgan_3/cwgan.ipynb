{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from mlp.data_providers import MNISTDataProvider, AugmentedCIFAR10DataProvider, AugmentedCIFAR100DataProvider, CIFAR100DataProvider, CIFAR10DataProvider\n",
    "from mlp.tf_layers import FCLayer, ConvLayer, max_pool_2x2\n",
    "from mlp.image_transforms import random_flip, random_crop, center_crop, random_flip_small\n",
    "from mlp.GAN_models import GAN, WasserstienGAN, CWGAN\n",
    "import mlp.tf_utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cPickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Seed a random number generator\n",
    "seed = 24102016 \n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'CWGAN_with_TTUR'\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # batch size for training\n",
    "z_dim = 100  \n",
    "gen_learning_rate = 2e-4\n",
    "disc_learning_rate = 2e-4\n",
    "optimizer_param = 0.9  # beta1 for Adam optimizer / decay for RMSProp\n",
    "iterations = 1e5  # No. of iterations to train model\n",
    "image_size = 32  # Size of actual images, Size of images to be generated at.\n",
    "model = 1  # Model to train. 0 - GAN, 1 - WassersteinGAN\n",
    "optimizer = \"Adam\"  # Optimizer to use for training\n",
    "gen_dim = 16  # dimension of first layer in generator\n",
    "mode = \"train\"  # train / visualize model\n",
    "logs_dir = '/home/ben/Dissertation/Multitask-Learning-With-GANs/4_cwgan_3/tf-log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = CIFAR100DataProvider(which_set='train', batch_size=batch_size)\n",
    "#train_data = CIFAR100DataProvider(which_set='train', batch_size=batch_size)\n",
    "#train_data.inputs = center_crop(train_data.inputs, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up model...\n",
      "Initializing network...\n",
      "Training CWGAN model...\n",
      "Time: 0.516834/itr, Step: 100, generator loss: 0.286539, discriminator_loss: -0.226323\n",
      "Time: 0.301517/itr, Step: 200, generator loss: 0.186883, discriminator_loss: -0.11647\n",
      "Time: 0.301485/itr, Step: 300, generator loss: 0.0069702, discriminator_loss: -0.113229\n",
      "Time: 0.301232/itr, Step: 400, generator loss: 0.0154631, discriminator_loss: -0.0691061\n",
      "Time: 0.312119/itr, Step: 500, generator loss: -0.122473, discriminator_loss: -0.0773889\n",
      "Saving images... Step: 500\n",
      "Time: 0.303511/itr, Step: 600, generator loss: 0.428218, discriminator_loss: -0.135569\n",
      "Time: 0.302392/itr, Step: 700, generator loss: 0.357727, discriminator_loss: -0.0327141\n",
      "Time: 0.302097/itr, Step: 800, generator loss: 0.326918, discriminator_loss: -0.070046\n",
      "Time: 0.302356/itr, Step: 900, generator loss: 0.237024, discriminator_loss: -0.0555693\n",
      "Time: 0.310601/itr, Step: 1000, generator loss: 0.167078, discriminator_loss: -0.0282843\n",
      "Saving images... Step: 1000\n",
      "Time: 0.305538/itr, Step: 1100, generator loss: 0.0436951, discriminator_loss: -0.0239526\n",
      "Time: 0.302375/itr, Step: 1200, generator loss: -0.130588, discriminator_loss: -0.0465212\n",
      "Time: 0.300528/itr, Step: 1300, generator loss: 0.0187489, discriminator_loss: -0.0616624\n",
      "Time: 0.301462/itr, Step: 1400, generator loss: -0.117661, discriminator_loss: -0.0728679\n",
      "Time: 0.30872/itr, Step: 1500, generator loss: -0.22675, discriminator_loss: -0.0265218\n",
      "Saving images... Step: 1500\n",
      "Time: 0.300218/itr, Step: 1600, generator loss: -0.266839, discriminator_loss: -0.0286413\n",
      "Time: 0.301521/itr, Step: 1700, generator loss: -0.240772, discriminator_loss: -0.0627551\n",
      "Time: 0.300171/itr, Step: 1800, generator loss: -0.215673, discriminator_loss: -0.0391041\n",
      "Time: 0.297822/itr, Step: 1900, generator loss: -0.22321, discriminator_loss: -0.0413624\n",
      "Time: 0.306818/itr, Step: 2000, generator loss: 0.0189084, discriminator_loss: -0.0364151\n",
      "Saving images... Step: 2000\n",
      "Time: 0.299607/itr, Step: 2100, generator loss: 0.189845, discriminator_loss: -0.0185135\n",
      "Time: 0.298412/itr, Step: 2200, generator loss: 0.281946, discriminator_loss: -0.0573902\n",
      "Time: 0.295824/itr, Step: 2300, generator loss: -0.202201, discriminator_loss: -0.0211812\n",
      "Time: 0.298558/itr, Step: 2400, generator loss: -0.187194, discriminator_loss: -0.0420026\n",
      "Time: 0.31051/itr, Step: 2500, generator loss: -0.24628, discriminator_loss: -0.0687199\n",
      "Saving images... Step: 2500\n",
      "Time: 0.301688/itr, Step: 2600, generator loss: 0.310609, discriminator_loss: -0.0436744\n",
      "Time: 0.302856/itr, Step: 2700, generator loss: 0.237693, discriminator_loss: -0.0344497\n",
      "Time: 0.301955/itr, Step: 2800, generator loss: 0.143335, discriminator_loss: -0.0233664\n",
      "Time: 0.304545/itr, Step: 2900, generator loss: -0.159504, discriminator_loss: -0.0326785\n",
      "Time: 0.307294/itr, Step: 3000, generator loss: 0.0862928, discriminator_loss: -0.0409622\n",
      "Saving images... Step: 3000\n"
     ]
    }
   ],
   "source": [
    "generator_dims = [128 * gen_dim, 64 * gen_dim // 2, 64 * gen_dim // 4, 3]\n",
    "discriminator_dims = [3, 64, 64 * 2, 64 * 4, 64 * 8, 1]\n",
    "\n",
    "if model == 0:\n",
    "    raise NotImplementedError\n",
    "    #model = GAN(z_dim, batch_size, train_data, image_size)\n",
    "elif model == 1:\n",
    "    model = CWGAN(z_dim, batch_size, train_data, image_size, 100, clip_values=(-0.01, 0.01), \n",
    "                  critic_iterations=5,\n",
    "                  penalise_gradient_norm=True, lmbda=10)\n",
    "else:\n",
    "    raise ValueError(\"Unknown model identifier - model=%d\" % model)\n",
    "\n",
    "model.create_network(generator_dims, discriminator_dims, model_name, optimizer, \n",
    "                     gen_learning_rate, disc_learning_rate, optimizer_param)\n",
    "model.initialize_network(logs_dir)\n",
    "\n",
    "if mode == \"train\":\n",
    "    model.train_model(int(1 + iterations))\n",
    "elif mode == \"visualize\":\n",
    "    model.visualize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_to_vec(class_name):\n",
    "    map_list = list(map.copy())\n",
    "    item_to_visualise = class_name\n",
    "    indx = map_list.index(item_to_visualise)\n",
    "    class_v = np.zeros([len(map)])\n",
    "    class_v[indx] = 1\n",
    "    class_v = [class_v for i in range(batch_size)]\n",
    "    return np.array(class_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = train_data.label_map\n",
    "a = np.array([0,0,1])\n",
    "i = np.where(a==1)[0][0]\n",
    "map[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sampling images from model...\")\n",
    "class_v = class_to_vec(\"sunflower\")\n",
    "z = np.random.uniform(-1.0, 1.0, size=[batch_size, 200 - class_v.shape[1]]).astype(np.float32)\n",
    "z = np.concatenate([z, class_v.astype(np.float32)], 1)\n",
    "\n",
    "feed_dict = {model.z_vec: z, model.train_phase: True}\n",
    "\n",
    "images = model.sess.run(model.gen_images, feed_dict=feed_dict)\n",
    "shape = [1, 1]\n",
    "utils.save_imshow_grid(images, model.logs_dir, \"generated_sample_\" + str(time.time()) + \".png\", shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate_sample(np.array(class_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gen_images[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
